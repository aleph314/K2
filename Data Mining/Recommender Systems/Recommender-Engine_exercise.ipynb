{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender  Engine\n",
    "Perhaps the most famous example of a recommender  engine in the Data Science world was the Netflix competition started in 2006, in which teams from all around the world competed to improve on Netflix's reccomendation algorithm.  The final prize of $1,000,000 was awarded to a team which developed a solution which had about a 10% increase in accuracy over Netflix's.  In fact, this competition resulted in the development of some new techniques which are still in use.  For more reading on this topic, see [Simon Funk's blog post](http://sifter.org/simon/journal/20061211.html)\n",
    "\n",
    "In this exercise, you will build a collaborative-filter recommendatin engine using both a cosine similarity approach and SVD (singular value decomposition).  Before proceding download the [MovieLens dataset](files.grouplens.org/datasets/movielens/ml-100k.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Pre-processing the Data\n",
    "First familiarize yourself with the data you downloaded, and then import the `u.data` file and take a look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>1997-12-04 15:55:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>1998-04-04 19:22:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>1997-11-07 07:18:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1997-11-27 05:02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>1998-02-02 05:33:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  itemid  rating           timestamp\n",
       "0     196     242       3 1997-12-04 15:55:49\n",
       "1     186     302       3 1998-04-04 19:22:22\n",
       "2      22     377       1 1997-11-07 07:18:36\n",
       "3     244      51       2 1997-11-27 05:02:03\n",
       "4     166     346       1 1998-02-02 05:33:16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/ml-100k/u.data', sep='\\t', header=None)\n",
    "df.columns = ['userid', 'itemid', 'rating', 'timestamp']\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'],unit='s')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building any recommendation engines, we'll have to get the data into a useful form.  Do this by first splitting the data into testing and training sets, and then by constructing two new dataframes whose columns are each unique movie and rows are each unique user, filling in `0` for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['userid'].unique()), len(df['itemid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dftrain, dftest = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1645)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftrain['userid'].unique()), len(dftrain['itemid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_items = set(df['itemid'].unique()) - set(dftrain['itemid'].unique())\n",
    "items = []\n",
    "for item in missing_items:\n",
    "    items.append([1, item, 0, np.nan])\n",
    "\n",
    "dftrain_filled = dftrain.append(pd.DataFrame(items, columns=dftrain.columns)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftrain_filled['userid'].unique()), len(dftrain_filled['itemid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 1406)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftest['userid'].unique()), len(dftest['itemid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_items = set(df['itemid'].unique()) - set(dftest['itemid'].unique())\n",
    "items = []\n",
    "for item in missing_items:\n",
    "    items.append([1, item, 0, np.nan])\n",
    "\n",
    "dftest_filled = dftest.append(pd.DataFrame(items, columns=dftest.columns)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 1682)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dftest_filled['userid'].unique()), len(dftest_filled['itemid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>itemid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "itemid  1     2     3     4     5     6     7     8     9     10    ...   \\\n",
       "userid                                                              ...    \n",
       "1        5.0   3.0   4.0   3.0   0.0   5.0   4.0   1.0   5.0   3.0  ...    \n",
       "2        4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "3        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "4        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "5        4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "\n",
       "itemid  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "userid                                                              \n",
       "1        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = pd.pivot_table(df, values='rating', index='userid', columns='itemid').fillna(0)\n",
    "# X.head()\n",
    "\n",
    "Xtrain = pd.pivot_table(dftrain_filled, values='rating', index='userid', columns='itemid').fillna(0)\n",
    "Xtest = pd.pivot_table(dftest_filled, values='rating', index='userid', columns='itemid').fillna(0)\n",
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "(942, 1682)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the data into a training and test set, using a ratio 80/20 for train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# Xtrain, Xtest = train_test_split(X, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cosine Similarity\n",
    "Building a recommendation engine can be thought of as \"filling in the holes\" in the sparse matrix you made above.  For example, take a look at the MovieLense data.  You'll see that that matrix is mostly zeros.  Our task here is to predict what a given user will rate a given movie depending on the users tastes.  To determine a users taste, we can use cosine similarity which is given by $$s_u^{cos}(u_k,u_a)\n",
    " = \\frac{ u_k \\cdot u_a }{ \\left \\| u_k \\right \\| \\left \\| u_a \\right \\| }\n",
    " = \\frac{ \\sum x_{k,m}x_{a,m} }{ \\sqrt{\\sum x_{k,m}^2\\sum x_{a,m}^2} }$$\n",
    "for users $u_a$ and $u_k$ on ratings given by $x_{a,m}$ and $x_{b,m}$.  This is just the cosine of the angle between the two vectors.  Likewise, this can also be calculated for the similarity between two items, $i_a$ and $i_b$, given by $$s_u^{cos}(i_m,i_b)\n",
    " = \\frac{ i_m \\cdot i_b }{ \\left \\| i_m \\right \\| \\left \\| i_b \\right \\| }\n",
    " = \\frac{ \\sum x_{a,m} x_{a,b} }{ \\sqrt{ \\sum x_{a,m}^2 \\sum x_{a,b}^2 } }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the similarity between two users is given by $$\\hat{x}_{k,m} = \\bar{x}_{k} + \\frac{\\sum\\limits_{u_a} s_u^{cos}(u_k,u_a) (x_{a,m})}{\\sum\\limits_{u_a}|s_u^{cos}(u_k,u_a)|}$$ and for items given by $$\\hat{x}_{k,m} = \\frac{\\sum\\limits_{i_b} s_u^{cos}(i_m,i_b) (x_{k,b}) }{\\sum\\limits_{i_b}|s_u^{cos}(i_m,i_b)|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these ideas to construct a class `cos_engine` which can be used to recommend movies for a given user.  Be sure to also test your algorithm, reporting its accuracy.  **Bonus:** Use adjusted cosine similiarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cos_engine():\n",
    "    def __init__(self, k, how='user'):\n",
    "        self.k = k\n",
    "        self.how = how\n",
    "    \n",
    "    def _cos_sim(self, x, y):\n",
    "        num = np.sum(x * y)\n",
    "        den = np.sum(x**2) * np.sum(y**2)\n",
    "        return num / np.sqrt(den)\n",
    "    \n",
    "    def _user_based_filtering(self, user, X):\n",
    "        sim = X.apply(lambda row: self._cos_sim(X.loc[user, :].values, row.values), axis=1)\n",
    "        sim = sim.drop(user, axis=0)\n",
    "        rec = sim.sort_values(ascending=False).head(self.k)\n",
    "        return rec\n",
    "    \n",
    "    def _item_based_filtering(self, item, X):\n",
    "        Xt = X.T\n",
    "        sim = Xt.apply(lambda row: self._cos_sim(Xt.loc[item, :].values, row.values), axis=1)\n",
    "        sim = sim.drop(item, axis=0)\n",
    "        rec = sim.sort_values(ascending=False).head(self.k)\n",
    "        return rec\n",
    "    \n",
    "    def fit(self, X):\n",
    "        if self.how == 'user':\n",
    "            Xfilled = []\n",
    "            for user in X.index.values:\n",
    "                ubf = self._user_based_filtering(user, X)\n",
    "                weighted_sum = np.sum(X.loc[ubf.index, :].values * ubf.values.reshape(-1, 1), axis=0)\n",
    "                Xfilled.append(weighted_sum / np.sum(np.abs(ubf.values)))\n",
    "            self.Xfilled = pd.DataFrame(np.array(Xfilled), index=X.index, columns=X.columns)\n",
    "        elif self.how == 'item':\n",
    "            Xtfilled = []\n",
    "            for item in X.columns.values:\n",
    "                ibf = self._item_based_filtering(item, X)\n",
    "                Xt = X.T\n",
    "                weighted_sum = np.sum(Xt.loc[ibf.index, :].values * ibf.values.reshape(-1, 1), axis=0)\n",
    "                Xtfilled.append(weighted_sum / np.sum(np.abs(ibf.values)))\n",
    "            self.Xfilled = pd.DataFrame(np.array(Xtfilled).T, index=X.index, columns=X.columns)\n",
    "        else:\n",
    "            print('Use either \"user\" or \"item\" for the parameter \"how\".')\n",
    "    \n",
    "    def predict(self, user, X):\n",
    "        try:\n",
    "            ratings = self.Xfilled.loc[user, :]\n",
    "            rated_items = X.loc[user, :] > 0\n",
    "            ratings = ratings[~rated_items]\n",
    "            return ratings.sort_values(ascending=False)\n",
    "        except AttributeError:\n",
    "            print('You have to fit the recommender first!')\n",
    "    \n",
    "    def score(self, X):\n",
    "        try:\n",
    "            return np.sum(np.sum(np.abs(self.Xfilled - X.where(X > 0)))) / X.where(X > 0).count().sum()\n",
    "        except AttributeError:\n",
    "            print('You have to fit the recommender first!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_ub = cos_engine(k=7)\n",
    "rec_ub.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4191191865071575"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_ub.Xfilled.loc[100, 258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemid\n",
       "327    2.433366\n",
       "748    1.723340\n",
       "343    1.607300\n",
       "303    1.549017\n",
       "245    1.387070\n",
       "873    1.301103\n",
       "331    1.180993\n",
       "329    1.141351\n",
       "322    1.116204\n",
       "882    1.050156\n",
       "Name: 100, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_ub.predict(100, Xtrain + Xtest).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.161008381608144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_ub.score(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "rec_ib = cos_engine(k=7, how='item')\n",
    "rec_ib.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5603889490414089"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_ib.Xfilled.loc[100, 258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemid\n",
       "301    3.699117\n",
       "312    3.259807\n",
       "748    2.870880\n",
       "307    2.591593\n",
       "304    2.553904\n",
       "245    2.426965\n",
       "311    2.312615\n",
       "327    2.293961\n",
       "343    2.199110\n",
       "319    2.109540\n",
       "Name: 100, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_ib.predict(100, Xtrain + Xtest).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.009026847268654"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_ib.score(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class cos_engine():\n",
    "#     def __init__(self, k, how='user'):\n",
    "#         self.k = k\n",
    "#         self.how = how\n",
    "    \n",
    "#     def _cos_sim(self, x, y):\n",
    "#         num = np.sum(x * y)\n",
    "#         den = np.sum(x**2) * np.sum(y**2)\n",
    "#         return num / np.sqrt(den)\n",
    "    \n",
    "#     def _user_based_filtering(self, user, X):\n",
    "#         sim = X.apply(lambda row: self._cos_sim(X.loc[user, :].values, row.values), axis=1)\n",
    "#         sim = sim.drop(user, axis=0)\n",
    "#         rec = sim.sort_values(ascending=False)#.head(self.k)\n",
    "#         return rec\n",
    "    \n",
    "#     def _item_based_filtering(self, item, X):\n",
    "#         Xt = X.T\n",
    "#         sim = Xt.apply(lambda row: self._cos_sim(Xt.loc[item, :].values, row.values), axis=1)\n",
    "#         sim = sim.drop(item, axis=0)\n",
    "#         rec = sim.sort_values(ascending=False)#.head(self.k)\n",
    "#         return rec\n",
    "    \n",
    "#     def fit(self, user, X):\n",
    "#         if self.how == 'user':\n",
    "#             ubf = self._user_based_filtering(user, X)\n",
    "#             rec = {}\n",
    "#             for item in X.columns.values:\n",
    "#                 temp = X.loc[ubf.index, item]\n",
    "#                 rec[item] = ubf.loc[temp > 0].head(self.k)\n",
    "#             self.rec = rec\n",
    "#         elif self.how == 'item':\n",
    "#             rec = {}\n",
    "#             for item in X.columns.values:\n",
    "#                 print('Fitting item ', item) # This is pretty slow...\n",
    "#                 ibf = self._item_based_filtering(item, X)\n",
    "#                 Xt = X.T\n",
    "#                 temp = Xt.loc[ibf.index, user]\n",
    "#                 rec[item] = ibf.loc[temp > 0].head(self.k)\n",
    "#             self.rec = rec\n",
    "#         else:\n",
    "#             print('Use either \"user\" or \"item\" for the parameter \"how\".')\n",
    "    \n",
    "#     def _predict_one(self, user, item, X):\n",
    "#         try:\n",
    "#             if self.how == 'user':\n",
    "#                 idx = self.rec[item].index\n",
    "#                 if len(idx) == 0:\n",
    "#                     return X.loc[user, item]\n",
    "#                 weighted_sum = np.sum(X.loc[idx, item].values * self.rec[item].values, axis=0)\n",
    "#                 return weighted_sum / np.sum(self.rec[item].values, axis=0)\n",
    "#             elif self.how == 'item':\n",
    "#                 Xt = X.T\n",
    "#                 idx = self.rec[item].index\n",
    "#                 if len(idx) == 0:\n",
    "#                     return X.loc[user, item]\n",
    "#                 weighted_sum = np.sum(Xt.loc[idx, user].values * self.rec[item].values, axis=0)\n",
    "#                 return weighted_sum / np.sum(self.rec[item].values, axis=0)\n",
    "#         except AttributeError:\n",
    "#             print('You have to fit the recommender first!')\n",
    "    \n",
    "#     def predict(self, user, X):\n",
    "#         pred = []\n",
    "#         for item in X.columns.values:\n",
    "#             pred.append(self._predict_one(user, item, X))\n",
    "#         return pd.Series(np.array(np.round(pred), dtype=int), index=X.columns)\n",
    "    \n",
    "#     def score(self, user, X):\n",
    "#         try:\n",
    "#             pred = self.predict(user, X)\n",
    "#             rated_items = X.loc[user, :] > 0\n",
    "#             user_ratings = X.loc[user, rated_items]\n",
    "#             pred_ratings = pred.loc[rated_items]\n",
    "#             return np.sum(user_ratings == pred_ratings) / len(user_ratings)\n",
    "#         except AttributeError:\n",
    "#             print('You have to fit the recommender first!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solution\n",
    "# Libraries\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "np.abs(cosine_similarity(Xtrain)).sum(axis=1).reshape(943, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVD\n",
    "Above we used Cosine Similarity to fill the holes in our sparse matrix.  Another, and much more popular, method for matrix completion is called a Singluar Value Decomposition.  SVD factors our data matrix into three smaller matricies, given by $$\\textbf{M} = \\textbf{U} \\bf{\\Sigma} \\textbf{V}^*$$ where $\\textbf{M}$ is our data matrix, $\\textbf{U}$ is a unitary matrix containg the latent variables in the user space, $\\bf{\\Sigma}$ is diagonal matrix containing the singular values of $\\textbf{M}$, and $\\textbf{V}$ is a unitary matrix containing the latent variables in the item space.  For more information on the SVD see the [Wikipedia article](https://en.wikipedia.org/wiki/Singular_value_decomposition).\n",
    "\n",
    "Numpy contains a package to estimate the SVD of a sparse matrix.  By making estimates of the matricies $\\textbf{U}$, $\\bf{\\Sigma}$, and $\\textbf{V}$, and then by multiplying them together, we can reconstruct an estimate for the matrix $\\textbf{M}$ with all the holes filled in.\n",
    "\n",
    "Use these ideas to construct a class `svd_engine` which can be used to recommend movies for a given user.  Be sure to also test your algorithm, reporting its accuracy.  **Bonus:** Tune any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class svd_engine():\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X):\n",
    "        if self.k <= np.min(X.shape):\n",
    "            U, S, V = np.linalg.svd(X)\n",
    "            Uk = np.dot(U[:,:self.k], np.sqrt(np.diag(S[:self.k])))\n",
    "            Vk = np.dot(np.sqrt(np.diag(S[:self.k])), V[:self.k,:])\n",
    "            self.Xfilled = pd.DataFrame(np.dot(Uk, Vk), index=X.index, columns=X.columns)\n",
    "        else:\n",
    "            print('k has to be smaller than the minimum dimension of X')\n",
    "    \n",
    "    def predict(self, user, X):\n",
    "        try:\n",
    "            ratings = self.Xfilled.loc[user, :]\n",
    "            rated_items = X.loc[user, :] > 0\n",
    "            ratings = ratings[~rated_items]\n",
    "            return ratings.sort_values(ascending=False)\n",
    "        except AttributeError:\n",
    "            print('You have to fit the recommender first!')\n",
    "    \n",
    "    def score(self, X):\n",
    "        try:\n",
    "            return np.sum(np.sum(np.abs(self.Xfilled - X.where(X > 0)))) / X.where(X > 0).count().sum()\n",
    "        except AttributeError:\n",
    "            print('You have to fit the recommender first!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_svd = svd_engine(k=100)\n",
    "rec_svd.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0395589377080148"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_svd.Xfilled.loc[100, 258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemid\n",
       "307    1.791480\n",
       "312    1.339279\n",
       "748    1.328989\n",
       "301    1.317524\n",
       "343    1.289623\n",
       "311    1.228762\n",
       "331    1.191659\n",
       "332    1.140870\n",
       "327    1.135568\n",
       "245    1.032280\n",
       "Name: 100, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_svd.predict(100, Xtrain + Xtest).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.917198706745735"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_svd.score(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in np.arange(10, 950, 10):\n",
    "    rec_svd = svd_engine(k=k)\n",
    "    rec_svd.fit(Xtrain)\n",
    "    scores.append([k, rec_svd.score(Xtest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2.340430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2.365737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>2.449003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>2.527992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>2.608181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k       MAE\n",
       "0  10  2.340430\n",
       "1  20  2.365737\n",
       "2  30  2.449003\n",
       "3  40  2.527992\n",
       "4  50  2.608181"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores, columns=['k', 'MAE']).sort_values(by='MAE').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in np.arange(2, 11):\n",
    "    rec_svd = svd_engine(k=k)\n",
    "    rec_svd.fit(Xtrain)\n",
    "    scores.append([k, rec_svd.score(Xtest)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>2.340430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>2.346365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>2.354198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>2.371857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2.389727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.422451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2.460086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.496903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.579625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k       MAE\n",
       "8  10  2.340430\n",
       "7   9  2.346365\n",
       "6   8  2.354198\n",
       "5   7  2.371857\n",
       "4   6  2.389727\n",
       "3   5  2.422451\n",
       "2   4  2.460086\n",
       "1   3  2.496903\n",
       "0   2  2.579625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores, columns=['k', 'MAE']).sort_values(by='MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_svd = svd_engine(k=10)\n",
    "rec_svd.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2613236758469246"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_svd.Xfilled.loc[100, 258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemid\n",
       "748    2.103909\n",
       "307    1.999920\n",
       "301    1.888959\n",
       "332    1.752203\n",
       "245    1.635943\n",
       "327    1.577040\n",
       "303    1.488295\n",
       "322    1.477374\n",
       "331    1.462423\n",
       "304    1.313905\n",
       "Name: 100, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_svd.predict(100, Xtrain + Xtest).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3404299215316"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_svd.score(Xtest)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
