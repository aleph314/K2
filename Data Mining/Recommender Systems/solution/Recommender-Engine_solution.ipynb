{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender  Engine\n",
    "Perhaps the most famous example of a recommender  engine in the Data Science world was the Netflix competition started in 2006, in which teams from all around the world competed to improve on Netflix's reccomendation algorithm.  The final prize of $1,000,000 was awarded to a team which developed a solution which had about a 10% increase in accuracy over Netflix's.  In fact, this competition resulted in the development of some new techniques which are still in use.  For more reading on this topic, see [Simon Funk's blog post](http://sifter.org/simon/journal/20061211.html)\n",
    "\n",
    "In this exercise, you will build a collaborative-filter recommendatin engine using both a cosine similarity approach and SVD (singular value decomposition).  Before proceding download the [MovieLens dataset](files.grouplens.org/datasets/movielens/ml-100k.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Pre-processing the Data\n",
    "First familiarize yourself with the data you downloaded, and then import the `u.data` file and take a look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data_movie_raw = pd.read_csv('../data/ml-100k/u.data', sep='\\t', names=header)\n",
    "data_movie_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building any recommendation engines, we'll have to get the data into a useful form.  Do this by first splitting the data into testing and training sets, and then by constructing two new dataframes whose columns are each unique movie and rows are each unique user, filling in `0` for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1671</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  1     2     3     4     5     6     7     8     9     10    ...   \\\n",
       "user_id                                                              ...    \n",
       "1         5.0   3.0   4.0   3.0   0.0   5.0   4.0   1.0   5.0   3.0  ...    \n",
       "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...    \n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "5         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    \n",
       "\n",
       "item_id  1671  1672  1673  1674  1675  1677  1678  1680  1681  1682  \n",
       "user_id                                                              \n",
       "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1652 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split into train and test sets\n",
    "data_train_raw, data_test_raw = train_test_split(data_movie_raw, train_size = 0.8)\n",
    "\n",
    "# Turning to pivot tables\n",
    "data_train = data_train_raw.pivot_table(index = 'user_id', columns = 'item_id', values = 'rating').fillna(0)\n",
    "data_test = data_test_raw.pivot_table(index = 'user_id', columns = 'item_id', values = 'rating').fillna(0)\n",
    "\n",
    "# Print the firest few rows\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the data into a training and test set, using a ratio 80/20 for train/test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cosine Similarity\n",
    "Building a recommendation engine can be thought of as \"filling in the holes\" in the sparse matrix you made above.  For example, take a look at the MovieLense data.  You'll see that that matrix is mostly zeros.  Our task here is to predict what a given user will rate a given movie depending on the users tastes.  To determine a users taste, we can use cosine similarity which is given by $$s_u^{cos}(u_k,u_a)\n",
    " = \\frac{ u_k \\cdot u_a }{ \\left \\| u_k \\right \\| \\left \\| u_a \\right \\| }\n",
    " = \\frac{ \\sum x_{k,m}x_{a,m} }{ \\sqrt{\\sum x_{k,m}^2\\sum x_{a,m}^2} }$$\n",
    "for users $u_a$ and $u_k$ on ratings given by $x_{a,m}$ and $x_{b,m}$.  This is just the cosine of the angle between the two vectors.  Likewise, this can also be calculated for the similarity between two items, $i_a$ and $i_b$, given by $$s_u^{cos}(i_m,i_b)\n",
    " = \\frac{ i_m \\cdot i_b }{ \\left \\| i_m \\right \\| \\left \\| i_b \\right \\| }\n",
    " = \\frac{ \\sum x_{a,m} x_{a,b} }{ \\sqrt{ \\sum x_{a,m}^2 \\sum x_{a,b}^2 } }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the similarity between two users is given by $$\\hat{x}_{k,m} = \\bar{x}_{k} + \\frac{\\sum\\limits_{u_a} s_u^{cos}(u_k,u_a) (x_{a,m})}{\\sum\\limits_{u_a}|s_u^{cos}(u_k,u_a)|}$$ and for items given by $$\\hat{x}_{k,m} = \\frac{\\sum\\limits_{i_b} s_u^{cos}(i_m,i_b) (x_{k,b}) }{\\sum\\limits_{i_b}|s_u^{cos}(i_m,i_b)|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these ideas to construct a class `cos_engine` which can be used to recommend movies for a given user.  Be sure to also test your algorithm, reporting its accuracy.  **Bonus:** Use adjusted cosine similiarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class cos_engine:\n",
    "    def __init__(self, data_all):\n",
    "        \"\"\"Constructor for cos_engine class\n",
    "        \n",
    "        Args:\n",
    "            data_all: Raw dataset containing all movies to build\n",
    "                    a list of movies already seen by each user.\n",
    "        \"\"\"\n",
    "        # Create copy of data\n",
    "        self.data_all = data_all.copy()\n",
    "        \n",
    "        # Now build a list of movies each of you has seen\n",
    "        self.seen = []\n",
    "        for user in data_all.user_id.unique():\n",
    "            cur_seen = {}\n",
    "            cur_seen[\"user\"] = user\n",
    "            cur_seen[\"seen\"] = self.data_all[data_all.user_id == user].item_id\n",
    "            self.seen.append(cur_seen)\n",
    "            \n",
    "        \n",
    "    def fit(self, data_train):\n",
    "        \"\"\"Performs cosine similarity on a sparse matrix data_train\n",
    "        \n",
    "        Args:\n",
    "            data_train: A pandas data frame data to estimate cosine similarity\n",
    "        \"\"\"\n",
    "        # Create a copy of the dataframe\n",
    "        self.data_train = data_train.copy()\n",
    "        \n",
    "        # Save the indices and column names\n",
    "        self.users = self.data_train.index\n",
    "        self.items = self.data_train.columns\n",
    "           \n",
    "        # Compute mean vectors\n",
    "        self.user_means = self.data_train.replace(0, np.nan).mean(axis = 1)\n",
    "        self.item_means = self.data_train.T.replace(0, np.nan).mean(axis = 1)\n",
    "        \n",
    "        # Get similarity matrices and compute sums for normalization\n",
    "        # For non adjusted cosine similarity, neglect subtracting the means.\n",
    "        self.data_train_adj = (self.data_train.replace(0, np.nan).T - self.user_means).fillna(0).T\n",
    "        self.user_cos = cosine_similarity(self.data_train_adj)\n",
    "        self.item_cos = cosine_similarity(self.data_train_adj.T)\n",
    "        \n",
    "        self.user_cos_sum = np.abs(self.user_cos).sum(axis = 1)\n",
    "        self.item_cos_sum = np.abs(self.item_cos).sum(axis = 1)\n",
    "        \n",
    "        self.user_cos_sum = self.user_cos_sum.reshape(self.user_cos_sum.shape[0], 1)\n",
    "        self.item_cos_sum = self.item_cos_sum.reshape(self.item_cos_sum.shape[0], 1)\n",
    "        \n",
    "    def predict(self, method = 'user'):\n",
    "        \"\"\"Predicts using Cosine Similarity\n",
    "            Args:\n",
    "                method: A string indicating what method to use, user or item.\n",
    "                    Default user.\n",
    "        Returns:\n",
    "            A pandas dataframe containing the prediction values\n",
    "        \"\"\"\n",
    "        # Store prediction locally and turn to dataframe\n",
    "        if method == 'user':\n",
    "            self.pred = self.user_means[:, np.newaxis] + ((self.user_cos @ self.data_train_adj) / self.user_cos_sum)\n",
    "            self.pred = pd.DataFrame(self.pred, index = data_train.index, columns = data_train.columns)\n",
    "        elif method == 'item':\n",
    "            self.pred = self.item_means[:, np.newaxis] + ((self.data_train @ self.item_cos) / self.item_cos_sum.T).T\n",
    "            self.pred = pd.DataFrame(self.pred, columns = data_train.index.values, index = data_train.columns)\n",
    "        \n",
    "        return(self.pred)\n",
    "        \n",
    "    def test(self, data_test, root = False):\n",
    "        \"\"\"Tests fit given test data in data_test\n",
    "        \n",
    "        Args:\n",
    "            data_test: A pandas dataframe containing test data\n",
    "            root: A boolean indicating whether to return the RMSE.\n",
    "                Default False\n",
    "        \n",
    "        Returns:\n",
    "            The Mean Squared Error of the fit if root = False, the Root Mean\\\n",
    "            Squared Error otherwise.\n",
    "        \"\"\"        \n",
    "        # Build a list of common indices (users) in the train and test set\n",
    "        row_idx = list(set(self.pred.index) & set(data_test.index))\n",
    "        \n",
    "        # Prime the variables for loop\n",
    "        err = []    # To hold the Sum of Squared Errors\n",
    "        N = 0       # To count preditions for MSE calculation\n",
    "        for row in row_idx:\n",
    "            # Get the rows\n",
    "            test_row = data_test.loc[row, :]\n",
    "            pred_row = self.pred.loc[row, :]\n",
    "            \n",
    "            # Get indices of nonzero elements in the test set\n",
    "            idx = test_row.index[test_row.nonzero()[0]]\n",
    "    \n",
    "            # Get only common movies\n",
    "            temp_test = test_row[idx]\n",
    "            temp_pred = pred_row[idx]\n",
    "            \n",
    "            # Compute error and count\n",
    "            temp_err = ((temp_pred - temp_test)**2).sum()\n",
    "            N = N + len(idx)\n",
    "            \n",
    "            err.append(temp_err)\n",
    "            \n",
    "        mse = np.sum(err) / N\n",
    "        \n",
    "        # Switch for RMSE\n",
    "        if root:\n",
    "            err = np.sqrt(mse)\n",
    "        else:\n",
    "            err = mse\n",
    "            \n",
    "        return(err)    \n",
    "    \n",
    "    def recommend(self, user, num_recs):\n",
    "        \"\"\"Tests fit given test data in data_test\n",
    "        \n",
    "        Args:\n",
    "            data_test: A pandas dataframe containing test data\n",
    "            root: A boolean indicating whether to return the RMSE.\n",
    "                Default False\n",
    "        \n",
    "        Returns:\n",
    "            The Mean Squared Error of the fit if root = False, the Root Mean\n",
    "            Squared Error otherwise.\n",
    "        \"\"\"\n",
    "        # Get list of already seen movies for this user\n",
    "        idx_seen = next(item for item in self.seen if item[\"user\"] == 2)[\"seen\"]\n",
    "        \n",
    "        # Remove already seen movies and recommend\n",
    "        rec = self.pred.loc[user, :].drop(idx_seen).nlargest(num_recs)\n",
    "        \n",
    "        return(rec.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "cos_en = cos_engine(data_movie_raw)\n",
    "cos_en.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.01054008245\n",
      "Reccomendations for user 1: [174 172 181 173  98]\n"
     ]
    }
   ],
   "source": [
    "# Predict using user similarity\n",
    "pred1 = cos_en.predict(method = 'user')\n",
    "err = cos_en.test(data_test, root = True)\n",
    "rec1 = cos_en.recommend(1, 5)\n",
    "\n",
    "print(\"RMSE:\", err)\n",
    "print(\"Reccomendations for user 1:\", rec1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.26912312232\n",
      "Reccomendations for item 1: [747 474 606 271 592]\n"
     ]
    }
   ],
   "source": [
    "# And now with item\n",
    "pred2 = cos_en.predict(method = 'item')\n",
    "err = cos_en.test(data_test, root = True)\n",
    "rec2 = cos_en.recommend(1, 5)\n",
    "\n",
    "print(\"RMSE:\", err)\n",
    "print(\"Reccomendations for item 1:\", rec2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVD\n",
    "Above we used Cosine Similarity to fill the holes in our sparse matrix.  Another, and much more popular, method for matrix completion is called a Singluar Value Decomposition.  SVD factors our data matrix into three smaller matricies, given by $$\\textbf{M} = \\textbf{U} \\bf{\\Sigma} \\textbf{V}^*$$ where $\\textbf{M}$ is our data matrix, $\\textbf{U}$ is a unitary matrix containg the latent variables in the user space, $\\bf{\\Sigma}$ is diagonal matrix containing the singular values of $\\textbf{M}$, and $\\textbf{V}$ is a unitary matrix containing the latent variables in the item space.  For more information on the SVD see the [Wikipedia article](https://en.wikipedia.org/wiki/Singular_value_decomposition).\n",
    "\n",
    "Numpy contains a package to estimate the SVD of a sparse matrix.  By making estimates of the matricies $\\textbf{U}$, $\\bf{\\Sigma}$, and $\\textbf{V}$, and then by multiplying them together, we can reconstruct an estimate for the matrix $\\textbf{M}$ with all the holes filled in.\n",
    "\n",
    "Use these ideas to construct a class `svd_engine` which can be used to recommend movies for a given user.  Be sure to also test your algorithm, reporting its accuracy.  **Bonus:** Tune any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "class svd_engine:\n",
    "    def __init__(self, data_all, k = 6):\n",
    "        \"\"\"Constructor for svd_engine class\n",
    "        \n",
    "        Args:\n",
    "            k: The number of latent variables to fit\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        \n",
    "        # Create copy of data\n",
    "        self.data_all = data_all.copy()\n",
    "        \n",
    "        # Now build a list of movies each you has seen\n",
    "        self.seen = []\n",
    "        for user in data_all.user_id.unique():\n",
    "            cur_seen = {}\n",
    "            cur_seen[\"user\"] = user\n",
    "            cur_seen[\"seen\"] = self.data_all[data_all.user_id == user].item_id\n",
    "            self.seen.append(cur_seen)\n",
    "            \n",
    "        \n",
    "    def fit(self, data_train):\n",
    "        \"\"\"Performs SVD on a sparse matrix data_train\n",
    "        \n",
    "        Args:\n",
    "            data_train: A pandas data frame data to estimate SVD\n",
    "            \n",
    "        Returns:\n",
    "            Matricies u, s, and vt of SVD\n",
    "        \"\"\"\n",
    "        # Save local copy of data\n",
    "        self.data_train = data_train.copy()\n",
    "        \n",
    "        # Compute adjusted matrix\n",
    "        self.user_means = self.data_train.replace(0, np.nan).mean(axis = 1)\n",
    "        self.item_means = self.data_train.T.replace(0, np.nan).mean(axis = 1)\n",
    "        self.data_train_adj = (self.data_train.replace(0, np.nan).T - self.user_means).fillna(0).T\n",
    "        \n",
    "        # Save the indices and column names\n",
    "        self.users = data_train.index\n",
    "        self.items = data_train.columns\n",
    "        \n",
    "        # Train the model\n",
    "        self.u, self.s, self.vt = svds(self.data_train_adj, k = self.k)\n",
    "        \n",
    "        return(self.u, np.diag(self.s), self.vt)\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"Predicts using SVD\n",
    "        \n",
    "        Returns:\n",
    "            A pandas dataframe containing the prediction values\n",
    "        \"\"\"\n",
    "        # Store prediction locally and turn to dataframe, adding the mean back\n",
    "        self.pred = pd.DataFrame(self.u @ np.diag(self.s) @ self.vt,\n",
    "                                 index = self.users,\n",
    "                                 columns = self.items)\n",
    "        self.pred = self.user_means[:, np.newaxis] + self.pred\n",
    "        return(self.pred)\n",
    "        \n",
    "    def test(self, data_test, root = False):\n",
    "        \"\"\"Tests fit given test data in data_test\n",
    "        \n",
    "        Args:\n",
    "            data_test: A pandas dataframe containing test data\n",
    "            root: A boolean indicating whether to return the RMSE.\n",
    "                Default False\n",
    "        \n",
    "        Returns:\n",
    "            The Mean Squared Error of the fit if root = False, the Root Mean\\\n",
    "            Squared Error otherwise.\n",
    "        \"\"\"        \n",
    "        # Build a list of common indices (users) in the train and test set\n",
    "        row_idx = list(set(self.pred.index) & set(data_test.index))\n",
    "        \n",
    "        # Prime the variables for loop\n",
    "        err = []    # To hold the Sum of Squared Errors\n",
    "        N = 0       # To count predictions for MSE calculation\n",
    "        for row in row_idx:\n",
    "            # Get the rows\n",
    "            test_row = data_test.loc[row, :]\n",
    "            pred_row = self.pred.loc[row, :]\n",
    "            \n",
    "            # Get indices of nonzero elements in the test set\n",
    "            idx = test_row.index[test_row.nonzero()[0]]\n",
    "    \n",
    "            # Get only common movies\n",
    "            temp_test = test_row[idx]\n",
    "            temp_pred = pred_row[idx]\n",
    "            \n",
    "            # Compute error and count\n",
    "            temp_err = ((temp_pred - temp_test)**2).sum()\n",
    "            N = N + len(idx)\n",
    "            \n",
    "            err.append(temp_err)\n",
    "            \n",
    "        mse = np.sum(err) / N\n",
    "        \n",
    "        # Switch for RMSE\n",
    "        if root:\n",
    "            err = np.sqrt(mse)\n",
    "        else:\n",
    "            err = mse\n",
    "            \n",
    "        return(err)    \n",
    "    \n",
    "    def recommend(self, user, num_recs):\n",
    "        \"\"\"Tests fit given test data in data_test\n",
    "        \n",
    "        Args:\n",
    "            data_test: A pandas dataframe containing test data\n",
    "            root: A boolean indicating whether to return the RMSE.\n",
    "                Default False\n",
    "        \n",
    "        Returns:\n",
    "            The Mean Squared Error of the fit if root = False, the Root Mean\\\n",
    "            Squared Error otherwise.\n",
    "        \"\"\"\n",
    "        # Get list of already seen movies for this user\n",
    "        idx_seen = next(item for item in self.seen if item[\"user\"] == 2)[\"seen\"]\n",
    "        \n",
    "        # Remove already seen movies and recommend\n",
    "        rec = self.pred.loc[user, :].drop(idx_seen).nlargest(num_recs)\n",
    "        \n",
    "        return(rec.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.983841087574\n",
      "Reccomendations for user 1: [173 172 181   7  89]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "svd_en = svd_engine(data_movie_raw, k = 20)\n",
    "svd_en.fit(data_train)\n",
    "svd_en.predict()\n",
    "err = svd_en.test(data_test, root = True)\n",
    "rec = svd_en.recommend(1, 5)\n",
    "\n",
    "print(\"RMSE:\", err)\n",
    "print(\"Reccomendations for user 1:\", rec.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall RMSE of about 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter tuning\n",
    "import matplotlib.pyplot as plt\n",
    "err = []\n",
    "for cur_k in range(1, 50):\n",
    "    svd_en = svd_engine(data_movie_raw, k = cur_k)\n",
    "    svd_en.fit(data_train)\n",
    "    svd_en.predict()\n",
    "    err.append(svd_en.test(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGHCAYAAABrpPKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fd9c525c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 50), err)\n",
    "plt.title('RMSE versus k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err.index(min(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 is the optimal value of k in this case.  Note that no cross-validation was performed!\n",
    "\n",
    "Now we'll build the best recommender and recommend 5 movies to each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the engine\n",
    "svd_en = svd_engine(data_movie_raw, k = 7)\n",
    "svd_en.fit(data_train)\n",
    "svd_en.predict()\n",
    "\n",
    "# Now make recommendations\n",
    "recs = []\n",
    "for user in data_movie_raw.user_id.unique():\n",
    "    temp_rec = svd_en.recommend(user, 5)\n",
    "    recs.append(temp_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([197, 9, 318, 357, 64], dtype='int64', name='item_id')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
