{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Dataset - Statistics Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "The data set we will use for this exercise comes from a Kaggle challenge and is often used for predictive analytics, namely to predict why the best and most experienced employees tend to leave the company.  We won't be using it for any predictive purposes here, but will instead use this data set to review many of the concepts explored in the Statistical Inference lectures.\n",
    "\n",
    "This data contains fields for various measures of employee performance and reported satisfaction levels, as well as categorical variables for events and salary level.  For now, just explore the data a bit to get a general idea of what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('HR_comma_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      "satisfaction_level       14999 non-null float64\n",
      "last_evaluation          14999 non-null float64\n",
      "number_project           14999 non-null int64\n",
      "average_montly_hours     14999 non-null int64\n",
      "time_spend_company       14999 non-null int64\n",
      "Work_accident            14999 non-null int64\n",
      "left                     14999 non-null int64\n",
      "promotion_last_5years    14999 non-null int64\n",
      "sales                    14999 non-null object\n",
      "salary                   14999 non-null object\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# print info, we have no nulls\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.612834</td>\n",
       "      <td>0.716102</td>\n",
       "      <td>3.803054</td>\n",
       "      <td>201.050337</td>\n",
       "      <td>3.498233</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>0.021268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248631</td>\n",
       "      <td>0.171169</td>\n",
       "      <td>1.232592</td>\n",
       "      <td>49.943099</td>\n",
       "      <td>1.460136</td>\n",
       "      <td>0.351719</td>\n",
       "      <td>0.425924</td>\n",
       "      <td>0.144281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "count        14999.000000     14999.000000    14999.000000   \n",
       "mean             0.612834         0.716102        3.803054   \n",
       "std              0.248631         0.171169        1.232592   \n",
       "min              0.090000         0.360000        2.000000   \n",
       "25%              0.440000         0.560000        3.000000   \n",
       "50%              0.640000         0.720000        4.000000   \n",
       "75%              0.820000         0.870000        5.000000   \n",
       "max              1.000000         1.000000        7.000000   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident          left  \\\n",
       "count          14999.000000        14999.000000   14999.000000  14999.000000   \n",
       "mean             201.050337            3.498233       0.144610      0.238083   \n",
       "std               49.943099            1.460136       0.351719      0.425924   \n",
       "min               96.000000            2.000000       0.000000      0.000000   \n",
       "25%              156.000000            3.000000       0.000000      0.000000   \n",
       "50%              200.000000            3.000000       0.000000      0.000000   \n",
       "75%              245.000000            4.000000       0.000000      0.000000   \n",
       "max              310.000000           10.000000       1.000000      1.000000   \n",
       "\n",
       "       promotion_last_5years  \n",
       "count           14999.000000  \n",
       "mean                0.021268  \n",
       "std                 0.144281  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe numeric columns\n",
    "# satisfaction_level and last_evaluation seems percentages\n",
    "# work_accident, left and promotion are booleans\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sales salary\n",
      "count   14999  14999\n",
      "unique     10      3\n",
      "top     sales    low\n",
      "freq     4140   7316\n",
      "['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "['low' 'medium' 'high']\n"
     ]
    }
   ],
   "source": [
    "# describe object columns and print unique values\n",
    "print(df[['sales', 'salary']].describe())\n",
    "print(df.sales.unique())\n",
    "print(df.salary.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability, Expectation Values, and Variance\n",
    "\n",
    "The concepts of probability, expectation values, and variance are the bedrock of statistical inference.  Let's begin by employing some of these concepts to see if we can find some interesting paths to go down which may provide some insight into the inner workings of this company.\n",
    "\n",
    "1. What is the probability that a randomly selected employee left the company?  What about experienced a work accident?  Also compute the probability that a randomly selected employee left the company and experienced a work accident.\n",
    "1. Compute the 25th, 50th, and 90th percentiles for the satisfaction level score for all employees that left the company.  Compare these results to the same percentiles for those that did not leave.  What can you say about the results?\n",
    "1. Compute the variance and standard deviation of hours worked.\n",
    "1. Compare the variance between the satisfaction levels of employees who left versus those who stayed.  Which is larger?  What does this mean?\n",
    "1. Compute the mean satisfaction level for each salary category.  Comment on your results.\n",
    "1. Given an employees salary level (low, medium, or high), calculate the probability that they worked more than two standard deviations of the average monthly hours across all groups.  In other words, compute\n",
    "$$P(hours > 2\\sigma \\vert salary ) = \\dfrac{P(salary \\vert hours > 2\\sigma) P(hours > 2\\sigma)}{P(salary)}$$\n",
    "1. What can you say about your results in part 6?\n",
    "1. Repeat parts 6 and 7 for \n",
    "$$P(left \\vert salary ) = \\dfrac{P(salary \\vert left) P(left)}{P(salary)}$$\n",
    "1. What is the odds ratio of an employee with a high salary getting a promotion within the past five years versus a low salary employee?  Comment on your results.\n",
    "1. Suppose we were to pull a random sample of size 50 of employee satisfaction levels.  What would approximately be the mean of this sample?  What would be the mean of, say, 10 sets of random samples?  Demonstrate your assertions by writing some python code to do just that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2380825388359224\n",
      "0.1446096406427095\n",
      "0.01126741782785519\n"
     ]
    }
   ],
   "source": [
    "n_employees = len(df)\n",
    "left = df.left.sum()\n",
    "accident = df.Work_accident.sum()\n",
    "accident_left = len(df[(df['Work_accident'] == 1) & (df['left'] == 1)])\n",
    "\n",
    "# probability that a randomly selected employee left the company\n",
    "print(left/n_employees)\n",
    "# probability that experienced a work accident\n",
    "print(accident/n_employees)\n",
    "# probability that a randomly selected employee left the company and experienced a work accident\n",
    "print(accident_left/n_employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees who left 25th, 50th and 90th percentile: 0.13, 0.41, 0.84\n",
      "Employees who stayed 25th, 50th and 90th percentile: 0.54, 0.69, 0.94\n"
     ]
    }
   ],
   "source": [
    "# Creating two dataframes, one for employees who left and one for those who stayed\n",
    "df_left = df[df['left'] == 1]\n",
    "df_stayed = df[df['left'] == 0]\n",
    "\n",
    "# Compute the 25th, 50th, and 90th percentiles for the satisfaction level score for all employees that left the company.\n",
    "print('Employees who left 25th, 50th and 90th percentile: {}, {}, {}'\n",
    "      .format(df_left.satisfaction_level.quantile(0.25),\n",
    "              df_left.satisfaction_level.quantile(0.5),\n",
    "              df_left.satisfaction_level.quantile(0.9)))\n",
    "# Compare these results to the same percentiles for those that did not leave. What can you say about the results?\n",
    "print('Employees who stayed 25th, 50th and 90th percentile: {}, {}, {}'\n",
    "      .format(df_stayed.satisfaction_level.quantile(0.25),\n",
    "              df_stayed.satisfaction_level.quantile(0.5),\n",
    "              df_stayed.satisfaction_level.quantile(0.9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a difference but before we draw any conclusion we would need to perform a hypothesis test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494.313174809979\n",
      "49.943099371284305\n"
     ]
    }
   ],
   "source": [
    "# Compute the variance and standard deviation of hours worked.\n",
    "print(df.average_montly_hours.var())\n",
    "print(df.average_montly_hours.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06966085873834325\n",
      "0.04713404022655909\n"
     ]
    }
   ],
   "source": [
    "# Compare the variance between the satisfaction levels of employees who left versus those who stayed.\n",
    "# Which is larger? What does this mean?\n",
    "print(df_left.satisfaction_level.var())\n",
    "print(df_stayed.satisfaction_level.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance in the satisfaction levels is larger for employees who left, so the satisfaction level for this employees is more spread out around the mean. This may indicate that the employees leaving the company have a level of satisfaction more variable than those who stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary\n",
       "high      0.637470\n",
       "low       0.600753\n",
       "medium    0.621817\n",
       "Name: satisfaction_level, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean satisfaction level for each salary category. Comment on your results.\n",
    "df.groupby('salary').satisfaction_level.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The satisfaction level increases with the salary, as expected. It seems though to be a more sensible difference between low and medium than medium and high salaries, but again we would need to test to see if the difference is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low salary level probability: 0.01353, 0.01353\n",
      "medium salary level probability: 0.00900, 0.00900\n",
      "high salary level probability: 0.00162, 0.00162\n"
     ]
    }
   ],
   "source": [
    "# Given an employees salary level (low, medium, or high), calculate the probability that\n",
    "# they worked more than two standard deviations of the average monthly hours across all groups.\n",
    "# In other words, compute P(hours > 2*sigma|salary) = P(salary|hours > 2*\\sigma)*P(hours > 2*sigma)/P(salary)\n",
    "\n",
    "# Creating a dataset for each salary level\n",
    "df_low = df[df['salary'] == 'low']\n",
    "df_medium = df[df['salary'] == 'medium']\n",
    "df_high = df[df['salary'] == 'high']\n",
    "\n",
    "# And one for employees who have worked more than two std above\n",
    "sigma_hours = df.average_montly_hours.mean() + 2*df.average_montly_hours.std()\n",
    "df_above = df[df['average_montly_hours'] > sigma_hours]\n",
    "P_hours = len(df_above) / n_employees\n",
    "\n",
    "for d, level in zip([df_low, df_medium, df_high], ['low', 'medium', 'high']):\n",
    "    P_salary = len(d) / n_employees\n",
    "    P_salary_hours = len(df_above[df_above['salary'] == level]) / len(df_above)\n",
    "    P = (P_salary_hours * P_hours) / P_salary\n",
    "    \n",
    "    P_hours_salary = len(d[d['average_montly_hours'] > sigma_hours]) / len(d)\n",
    "    print('{} salary level probability: {:.5f}, {:.5f}'.format(level, P, P_hours_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you say about your results in part 6?**\n",
    "\n",
    "There seems to be a clear trend and difference between the probability that an employee who worked more time is in a given salary level: the employee is more probable to be found in low and medium salary levels than high. This difference, though it seems quite marked, should be verified through a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low salary level probability: 0.29688, 0.29688\n",
      "medium salary level probability: 0.20431, 0.20431\n",
      "high salary level probability: 0.06629, 0.06629\n"
     ]
    }
   ],
   "source": [
    "# Repeat parts 6 and 7 for P(left|salary) = P(salary|left)*P(left)/P(salary)\n",
    "\n",
    "P_left = len(df_left) / n_employees\n",
    "\n",
    "for d, level in zip([df_low, df_medium, df_high], ['low', 'medium', 'high']):\n",
    "    P_salary = len(d) / n_employees\n",
    "    P_salary_left = len(df_left[df_left['salary'] == level]) / len(df_left)\n",
    "    P = (P_salary_left * P_left) / P_salary\n",
    "    \n",
    "    P_left_salary = len(d[d['left'] == 1]) / len(d)\n",
    "    print('{} salary level probability: {:.5f}, {:.5f}'.format(level, P, P_left_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above the probability that an employee left the company given a certain salary level is higher for low and medium salary levels than for high ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0582053354890865\n",
      "0.009021323127392018\n"
     ]
    }
   ],
   "source": [
    "# What is the odds ratio of an employee with a high salary getting a promotion\n",
    "# within the past five years versus a low salary employee? Comment on your results.\n",
    "\n",
    "print(len(df_high[df_high['promotion_last_5years'] == 1]) / len(df_high))\n",
    "print(len(df_low[df_low['promotion_last_5years'] == 1]) / len(df_low))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability is sensibly higher for high salary level than low.\n",
    "\n",
    "I think this is in part explained because if you are in a high salary level you had to get there by being promoted, instead if you are in a low level there is some chance that you are a newly arrived employee and you couldn't have got a promotion yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suppose we were to pull a random sample of size 50 of employee satisfaction levels.**\n",
    "\n",
    "1. What would approximately be the mean of this sample? Somewhere near the mean of the entire dataset, but not that near because the sample size isn't that big.\n",
    "2. What would be the mean of, say, 10 sets of random samples? Closer to the mean of the dataset because we have taken more samples, even the same size of each sample hasn't changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mean: 0.6128335222348166\n",
      "Sample mean: 0.5707999999999999\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate your assertions by writing some python code to do just that.\n",
    "\n",
    "random.seed(7)\n",
    "size = 50\n",
    "s = random.sample(range(0, n_employees), size)\n",
    "print('Dataset mean: {}\\nSample mean: {}'.format(df.satisfaction_level.mean(), df.iloc[s].satisfaction_level.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mean: 0.6128335222348166\n",
      "Mean of sample means: 0.6120599999999999\n"
     ]
    }
   ],
   "source": [
    "random.seed(7)\n",
    "\n",
    "size = 50\n",
    "n_samples = 10\n",
    "mean = 0\n",
    "\n",
    "for i in range(n_samples):\n",
    "    s = random.sample(range(0, n_employees), size)\n",
    "    mean += df.iloc[s].satisfaction_level.mean()\n",
    "    \n",
    "mean = mean / n_samples\n",
    "print('Dataset mean: {}\\nMean of sample means: {}'.format(df.satisfaction_level.mean(), mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Distributions and The Central Limit Theorem\n",
    "### The Bernoulli Distribution\n",
    "Bernoulli distributions are the result of a random variable with a binary outcome, like a coin flip or medical test giving a positive or negative result.  Typically we represent the outcomes of a Bernoulli Random variable $X$ of only taking values of 0 or 1, with probabilities $p$ and $1 - p$ respectively, mean $p$, variance $p(1 - p)$, and PMF given by\n",
    "\n",
    "$$ P(X = x) = p^x (1 - p)^{1 - x} $$\n",
    "\n",
    "Where $x$ is the outcome and $p$ is the probability of the positive outcome (1).\n",
    "\n",
    "Bernoulli random variables crop up very often in statistical analysis &mdash; most often in the form of Binomial trials, or, as a sum of independent Bernoulli variables with PMF given by \n",
    "$$ P(X = x) = {n \\choose x} p^x (1 - p)^{n - x} $$\n",
    "where\n",
    "$$ {n \\choose x} = \\frac{n!}{x!(n - x)!} $$\n",
    "In this exercise you'll take a look at the HR data and apply these concepts to gain some insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the HR data, answer the following.\n",
    "1. Which variables in the HR data can be said to be Bernoulli random variables?\n",
    "2. For the variables you identified in part 1, compute the probabilities $p_k$, of each having a positive $(x = 1)$ result, where $k$ is a placeholder for each variable.\n",
    "3. Compute the variance of each of the variables in part 2 using $p_k$ as described above.\n",
    "4. For each of the k variables, compute the probability of randomly selecting 3500 employees with a positive result.  Comment on your answer.\n",
    "5. For each of the k variables, compute the probability of randomly selecting 3500 **or less** with a positive result.  Comment on your answer.\n",
    "6. Now plot both the PMF and CDF as a function of the number of drawn samples for each of the k variables.  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal Distribution\n",
    "The Normal distribution (or sometimes called the Bell Curve or Gaussian) is by far the most prevalent and useful distribution in any field that utilizes statistical techniques.  In fact, in can be shown that the means of random variables sampled repeatedly from **any** distribution eventually form a normal given a sufficiently large sample size.\n",
    "\n",
    "A normal distribution is characterized by the PDF given by\n",
    "$$p(x|\\mu,\\sigma) = \\frac{1}{\\sqrt{(2\\pi\\sigma^2)}}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mu$ is the mean and $\\sigma^2$ is the variance, thus the distribution is characterized by mean and variance alone.  In this exercise, you'll examine some of the variables in the HR dataset and construct some normal distributions approximating them.\n",
    "\n",
    "Using the HR data, answer the following\n",
    "\n",
    "1. Which variables may be approximately normal?\n",
    "2. For the variables in part 1, plot some histograms.\n",
    "3. Compute the mean and variance for each of the variables used in parts 1 and 2.\n",
    "4. Using the mean and variance in part 3, construct normal distributions for each and overlay them on top of the histograms you made in part one.  Are they well approximated by normals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Poisson Distribution\n",
    "The Poisson distribution is very versatile but is typically used to model counts per unit time or space, such as the number of ad clicks or arriving flights, each per unit time. It has a PDF given by\n",
    "$$ P(X = x, \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!} $$\n",
    "where the mean and variance are both equal to $\\lambda$\n",
    "\n",
    "Using the HR data, answer the following.\n",
    "\n",
    "1. What variables would be good candidates for modeling with a Poisson distribution?\n",
    "2. For each variable in part 1, divide each by salary and fit a Poisson distribution to each.\n",
    "3. For each salary level, compute the probability of obtaining at least the mean of each variable &mdash; regardless of salary level &mdash; by using the Poisson distributions you constructed in part 2.  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Central Limit Theorem\n",
    "The Central Limit Theorem is perhaps one of the most remarkable results in statistics and mathematics in general.  In short, it says that the distribution of means of independent random variables, sampled from **any** distribution, tends to approach a normal distribution as the sample size increases.\n",
    "\n",
    "An example of this would be taking a pair of dice, rolling them, and recording the mean of each result.  The Central Limit Theorem states, that after enough rolls, the distribution of the means will be approximately normal.  Stated formally, the result is\n",
    "    $$ \\bar{X_n} \\sim N(\\mu, \\sigma^2/n) = \\frac{\\sqrt{n}}{\\sigma \\sqrt{2\\pi}}e^{-n(\\bar{X_n} - \\mu)^2/\\sigma^2}$$\n",
    "In this exercise, you'll conduct some simulation experiments to explore this idea.\n",
    "\n",
    "Using the HR data, answer the following.\n",
    "1. Choose two variables which may be good candidates to test this theorem.\n",
    "2. Using the variables chosen in part 1, randomly select a set of `n = 10` samples and take the mean.  Repeat this 1000 times for each variable.\n",
    "3. Plot a histogram for each variable used in part 2.  Comment on your results.\n",
    "4. Repeat parts 2-3 for `n = 100`, `n = 500`, and `n = 1000`.  Comment on your results.\n",
    "5. Overlay an normal curve on your `n = 1000` plots, using the mean and variance computed from the data.  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "Hypothesis testing is essentially using the data to answer questions of interest.  For example, does a new medication provide any benefit over placebo?  Or is a subset of the population disproportionately more susceptible to a particular disease?  Or is the difference between two companies profits' significant or due to chance alone?\n",
    "\n",
    "Before doing some hypothesis testing on the HR data, recall that hypothesis typically come in pairs of the form $H_0$, called the null hypothesis, versus $H_a$, called the alternative hypothesis.  The null hypothesis represents the \"default\" assumption -- that a medication has no effect for example, while the alternative hypothesis represents what exactly we are looking to discover, in the medication case, whether it provides a significant benefit.  Another common case is testing the difference between two means.  Here, the null hypothesis is that there is no difference between two population means, whereas the alternative hypothesis is that there is a difference.  Stated more precisely\n",
    "$$H_0: \\mu_1 - \\mu_2 = 0$$\n",
    "$$H_a: \\mu_1 - \\mu_2 \\ne 0$$\n",
    "\n",
    "Hypotheses are usually tested by constructing a confidence interval around the test statistic and selecting a \"cut-off\" significance level denoted $\\alpha$.  A typical $\\alpha$ significance is 0.05 and is often called a \"p-value\".  If a test produces a p-value of $\\alpha$ or below, then the null hypothesis can be rejected, strengthening the case of the alternative hypothesis.  It is very important to remember that hypothesis testing can only tell you if your hypothesis is statistically significant -- this does **not** mean that your result may be scientifically significant which requires much more evidence.\n",
    "\n",
    "In this exercise you'll explore the HR data more and test some hypothesis.\n",
    "\n",
    "Using the HR data, answer the following.\n",
    "\n",
    "1. Compute a confidence interval for satisfaction levels, at the 95% confidence level, of employees who left the company and those who didn't.  Do this using both a t distribution and a normal.  Comment on your results.\n",
    "2. Use a t-test to test the hypothesis that employees who left the company, had lower satisfaction levels than those who did not.  If significant, is the mean difference?  Comment on your results.  (Hint: Do the two populations have equal variance?)\n",
    "3. Fit a normal curve to each group in part 2 and put them on the same plot next to each other.  Comment on your results.\n",
    "4. Test the hypothesis that the satisfaction level between each salary group, denoted k, differs signicantly from the mean.  Namely\n",
    "    - $H_0: \\mu - \\mu_k = 0$\n",
    "    - $H_a: \\mu - \\mu_k \\ne 0$\n",
    "5. How would you interpret your results in part 5?\n",
    "6. Generate plots for part 5 as you did in part 3.  What conclusions can you draw from the plot?\n",
    "7. Repeat parts 4-6 on a hypothesis of your choosing.\n",
    "8. Recall that Power is the probability of failing to reject the null hypothesis when it is false (thus more power is good).  Compute the power for the hypothesis that the satisfaction level of high paid employees is different than that of medium paid employees using a t distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "Bootstrapping is an immensely useful technique in practice.  Very often you may find yourself in a situation where you want to compute some statistic, but lack sufficient data to do so.  Bootstrapping works as a remedy to this problem.\n",
    "\n",
    "Recall that the bootstrapping algorithm breaks down as follows:\n",
    "1. Sample n observations with replacement from the observed data resulting in one simulated complete data set. \n",
    "1. Take the statistic of the simulated data set\n",
    "1. Repeat these two steps B times, resulting in B simulated statistics\n",
    "1. These statistics are approximately drawn from the sampling distribution of the statistic of n observations\n",
    "    - This is a lot like what you did when drawing many sample means\n",
    "\n",
    "In this exercise you will implement this algorithm on the HR data.\n",
    "\n",
    "Write a function that can perform bootrapping for the median of a set of n samples in the HR data set.  Test this function on the `satisfaction_level` with `n = 100` and `b = 100` and compare your results to the true median.  Also compute the standard deviation of the bootstrapped median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
