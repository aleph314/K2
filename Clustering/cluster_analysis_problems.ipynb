{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis: Partitioning (Segmentation)\n",
    "\n",
    "Create a set of functions that can be used together to segment satellite  images into similar regions using k-means clustering, and then create and apply a color mask to areas of water. Specifically:\n",
    "\n",
    "1. Determine the best image pre-processing method that will do the best job of smoothing similar colors\n",
    "    - sub-regions in satellite  images tend to have a lot of color variation / texture that can negatively impact the performance of segmentation when using something like k-means clustering\n",
    "    - use scikit-image for this\n",
    "2. Create a pre_process funcition that returns a pre-processed version of the image that has the following parameters\n",
    "    - img : the input image\n",
    "    - p : whatever parameter belongs to the method you chose from (1)\n",
    "    - multichannel : Bool for whether or not the image has multiple channels (e.g. RGB)\n",
    "        + only if necessary\n",
    "3. Create one or more functions that together are used for segmenting an image using k-means clustering\n",
    "4. Create a function to help automate the selection of parameters to use in the method from (1) and for k-means \n",
    "    - it should iterate over a set of 6 possible test parameter combinations\n",
    "        + each combination is (pre-processing parameter, n_clusters for kmeans)\n",
    "    - each iteration should segment the provided satellite image using the the given combination\n",
    "    - return a single image that displays the segmented versions in a 3x2 grid\n",
    "    - visually inspect the 6 versions and decide on the best combination to use\n",
    "5. Use the parameters determined above to create a version of the original image that has a single-colored mask wherever water appears in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis: Target Study (Young People Survey) using agglomerative clustering\n",
    "\n",
    "The dataset provided can be summarized as follows:\n",
    "\n",
    "In 2013, students of the Statistics class at FSEV UK were asked to invite their friends to participate in this survey.\n",
    "\n",
    "* The data file (responses.csv) consists of 1010 rows and 150 columns (139 integer and 11 categorical).\n",
    "* For convenience, the original variable names were shortened in the data file. See the columns.csv file if you want to match the data with the original names.\n",
    "* The data contain missing values.\n",
    "* The survey was presented to participants in both electronic and written form.\n",
    "* The original questionnaire was in Slovak language and was later translated into English.\n",
    "* All participants were of Slovakian nationality, aged between 15-30.\n",
    "* Numerical columns are primarily in range [1,5], except for values like weight and height.\n",
    "\n",
    "Your task is to use agglomerative (hierarchical) cluster analysis to analyze this data. Specifically:\n",
    "\n",
    "1. Modify the original data\n",
    "    - Remove any categorical variables from the data\n",
    "        - categorical doesn't work with this clustering method\n",
    "        - we aren't concerned with creating dummy vars\n",
    "    - Add a new column for gender, but make it binary\n",
    "    - Remove any rows with null values\n",
    "2. Use scipy to cluster and create a dendrogram of the cluster hierarchy for the data\n",
    "    - use the ward method\n",
    "    - exclude gender for now\n",
    "    - plot the dendrogram\n",
    "    - determine a good cutoff value\n",
    "    - re-plot the dendrogram with a line for the cutoff and determine the number of clusters this gives\n",
    "3. Create a new dendrogram that truncates using the determined number of clusters and show number of points per cluster\n",
    "    - hint: check the truncate_mode options\n",
    "4. Use the scipy `hierarchy.fcluster` method to get cluster labels for 16 clusters from the data\n",
    "    - hint: threshold\n",
    "    - create a column for the labels in the data\n",
    "    - compare the class distributions between genders\n",
    "    - reset the threshold and create a new set of labels that will give only two classes\n",
    "        - add this as a second column for labels\n",
    "    - compare the distributions of these two classes between genders\n",
    "        - does it seem that the two top-level clusters are gender-specific?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summarization / Color Quantization\n",
    "\n",
    "Given a set of images, use k-means to perform color quantization to reduce the number of distinct colors in each image. Specifically\n",
    "\n",
    "1. Create a quantize function that takes an image and the desired number of colors as parameters and\n",
    "    - performs color quantization using k-means\n",
    "        - reduce the number of colors in the image\n",
    "    - return the color-reduced image\n",
    "    - make sure it can handle both greyscale and multichannel images\n",
    "    - run this function on the image titled bw.jpg and view the result\n",
    "2. Create a batch_reduce function that takes a list of file names and number of desired colors as parameters and\n",
    "    - imports/opens each image in the list of file names\n",
    "    - uses the quantize function to reduce the number of colors in each image\n",
    "    - saves the original and reduced images in separate folders\n",
    "3. Run the batch_reduce on everything in the provided images folder and then compare original and reduced file sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with PCA and Machine Learning\n",
    "\n",
    "Create a simple custom pipeline that does the following with the survey data:\n",
    "\n",
    "- train/test split using 67% of the data for the train\n",
    "- perform PCA and select the number of components that retain at least 90% of the variance\n",
    "- perform k-means clustering on the PCA training set (scki-kit learn) with 16 clusters\n",
    "- apply the cluster labels to the training set\n",
    "- fit the labeled training set using a Random Forest Classifier\n",
    "- make predictions on the test set using both the k-means and rfc models\n",
    "- compare the two model predictions using class-wise precision, recall, and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
